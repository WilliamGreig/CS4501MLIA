{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "from typing import Dict, SupportsRound, Tuple, Any\n",
    "from os import PathLike\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import torch,gc\n",
    "from torch.autograd import grad\n",
    "from torch.autograd import Variable\n",
    "import torch.fft ############### Pytorch >= 1.8.0\n",
    "import torch.nn.functional as F\n",
    "import SimpleITK as sitk\n",
    "import os, glob\n",
    "import json\n",
    "import subprocess\n",
    "import sys\n",
    "from PIL import Image\n",
    "import torch.nn.functional as nnf\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR,CosineAnnealingWarmRestarts,StepLR\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "from easydict import EasyDict as edict\n",
    "import random\n",
    "import yaml\n",
    "# currentdir = os.path.dirname(os.path.realpath(__file__))\n",
    "# parentdir = os.path.dirname(currentdir)\n",
    "# sys.path.append(parentdir)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda\"\n",
    "else:\n",
    "    dev = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################Parameter Loading#######################\n",
    "def read_yaml(path):\n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            file = edict(yaml.load(f, Loader=yaml.FullLoader))\n",
    "        return file\n",
    "    except:\n",
    "        print('NO FILE READ!')\n",
    "        return None\n",
    "para = read_yaml('./parameters.yml')\n",
    "\n",
    "xDim = para.data.x \n",
    "yDim = para.data.y\n",
    "zDim = para.data.z\n",
    "\n",
    "def loss_Reg(y_pred):\n",
    "        # For 3D reg\n",
    "        # dy = torch.abs(y_pred[:, :, 1:, :, :] - y_pred[:, :, :-1, :, :])\n",
    "        # dx = torch.abs(y_pred[:, :, :, 1:, :] - y_pred[:, :, :, :-1, :])\n",
    "        # dz = torch.abs(y_pred[:, :, :, :, 1:] - y_pred[:, :, :, :, :-1])\n",
    "        # dy = dy * dy\n",
    "        # dx = dx * dx\n",
    "        # dz = dz * dz\n",
    "        # d = torch.mean(dx) + torch.mean(dy) + torch.mean(dz)\n",
    "        # grad = d / 3.0\n",
    "\n",
    "        dy = torch.abs(y_pred[:, :, 1:, :] - y_pred[:, :, :-1, :])\n",
    "        dx = torch.abs(y_pred[:, :, :, 1:] - y_pred[:, :, :, :-1])\n",
    "\n",
    "        dy = dy * dy\n",
    "        dx = dx * dx\n",
    "        d = torch.mean(dx) + torch.mean(dy) \n",
    "        grad = d / 2.0\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################Data Loading##########################\n",
    "readfilename = './2D_Bulleye_full/test/test' + '.json' #### Read the json file from the 2DBrainfull_normalized\n",
    "datapath = './2D_Bulleye_full/test/'\n",
    "data = json.load(open(readfilename, 'r'))\n",
    "outputs = []\n",
    "keyword = 'test'\n",
    "# outputs = np.array(outputs)\n",
    "\n",
    "for i in range (0,len(data[keyword])):\n",
    "    filename_src = datapath + data[keyword][i]['source']\n",
    "#     print(filename_src)\n",
    "    itkimage_src = sitk.ReadImage(filename_src)\n",
    "    source_scan = sitk.GetArrayFromImage(itkimage_src)\n",
    "    filename_tar = datapath + data[keyword][i]['target']\n",
    "    itkimage_tar = sitk.ReadImage(filename_tar)\n",
    "    target_scan = sitk.GetArrayFromImage(itkimage_tar)\n",
    "    pair = np.concatenate((source_scan, target_scan), axis=0)\n",
    "    outputs.append(pair)\n",
    "\n",
    "test = torch.FloatTensor(outputs)\n",
    "print (test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Check initilization'''\n",
    "from losses import MSE, Grad\n",
    "#################Network optimization########################\n",
    "from networks import DiffeoDense  \n",
    "net = []\n",
    "for i in range(3):\n",
    "    temp = DiffeoDense(inshape = (xDim,yDim),\n",
    "\t\t\t\t nb_unet_features= [[16, 32],[ 32, 32, 16, 16]],\n",
    "                 nb_unet_conv_per_level=1,\n",
    "                 int_steps=7,\n",
    "                 int_downsize=2,\n",
    "                 src_feats=1,\n",
    "                 trg_feats=1,\n",
    "                 unet_half_res= True)\n",
    "    net.append(temp)\n",
    "net = net[0].to(dev)\n",
    "# print (net)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size = para.solver.batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "running_loss = 0 \n",
    "running_loss_val = 0\n",
    "template_loss = 0\n",
    "printfreq = 1\n",
    "sigma = 0.02\n",
    "repara_trick = 0.0\n",
    "loss_array = torch.FloatTensor(para.solver.epochs,1).fill_(0)\n",
    "loss_array_val = torch.FloatTensor(para.solver.epochs,1).fill_(0)\n",
    "\n",
    "\n",
    "gradv_batch = torch.cuda.FloatTensor(para.solver.batch_size, 3, xDim, yDim).fill_(0).contiguous()\n",
    "defIm_batch = torch.cuda.FloatTensor(para.solver.batch_size, 1, xDim, yDim).fill_(0).contiguous()\n",
    "temp = torch.cuda.FloatTensor(para.solver.batch_size, 3, xDim, yDim).fill_(0).contiguous()\n",
    "transformations = torch.cuda.FloatTensor(para.solver.batch_size, 3, xDim, yDim).fill_(0).contiguous() \n",
    "atlas = torch.cuda.FloatTensor(1, 1, xDim, yDim).fill_(0).contiguous()\n",
    "atlas.requires_grad=True\n",
    "\n",
    "gradv_batch_val = torch.cuda.FloatTensor(1, 3, xDim, yDim).fill_(0).contiguous()\n",
    "defIm_batch_val = torch.cuda.FloatTensor(1, 1, xDim, yDim).fill_(0).contiguous() \n",
    "temp_val = torch.cuda.FloatTensor(1, 3, xDim, yDim).fill_(0).contiguous()\n",
    "deform_size = [1, xDim, yDim]\n",
    "\n",
    "if(para.model.loss == 'L2'):\n",
    "    criterion = nn.MSELoss()\n",
    "elif (para.model.loss == 'L1'):\n",
    "    criterion = nn.L1Loss()\n",
    "if(para.model.optimizer == 'Adam'):\n",
    "    optimizer = optim.Adam(net.parameters(), lr= para.solver.lr)\n",
    "elif (para.model.optimizer == 'SGD'):\n",
    "    optimizer = optim.SGD(net.parameters(), lr= para.solver.lr, momentum=0.9)\n",
    "if (para.model.scheduler == 'CosAn'):\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=len(testloader), eta_min=0)\n",
    "\n",
    "optimizer_template = optim.Adam(net.parameters(), lr= para.solver.lr)\n",
    "scheduler_template = CosineAnnealingLR(optimizer_template, T_max=len(testloader), eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './saved_models/reg_model.pth'\n",
    "\n",
    "# model = net()\n",
    "# model.load_state_dict(torch.load(PATH))\n",
    "# model.eval()\n",
    "\n",
    "net = torch.load(PATH)\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##################Testing###################################\n",
    "for epoch in range(para.solver.epochs):\n",
    "    total= 0; \n",
    "    total_val = 0; \n",
    "    total_template = 0; \n",
    "    loss1 = 0\n",
    "    loss_2 = 0\n",
    "    net.eval()\n",
    "#     print('epoch:', epoch)\n",
    "    for j, image_data in enumerate(testloader):\n",
    "        inputs = image_data.to(dev)\n",
    "        b, c, w, h = inputs.shape\n",
    "        optimizer.zero_grad()\n",
    "        src_bch = inputs[:,0,...].reshape(b,1,w,h)\n",
    "        tar_bch = inputs[:,1,...].reshape(b,1,w,h)\n",
    "        pred = net(src_bch, tar_bch, registration = True)     \n",
    "        loss = criterion(pred[0], tar_bch) \n",
    "        loss2 = loss_Reg(pred[1])\n",
    "#         loss2 = np.linalg.norm(pred[3].detach().cpu())\n",
    "        loss_total = loss + 0.1*loss2   ### tune 0.1 with different values\n",
    "        loss_total.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        running_loss += loss_total.item()\n",
    "        # print('[%d, %5d] loss: %.3f' %\n",
    "        #     (epoch + 1, i + 1, running_loss ))\n",
    "        total += running_loss\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        loss1 += loss.item()\n",
    "        loss_2 += 0.1*loss2.item()\n",
    "        \n",
    "#     print ('total testing loss:', total, loss1, loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Save the deformed image and transformation fields ####\n",
    "#### pred[0] is the deformed images\n",
    "### pred[1] is the transformation fields"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.8.1",
   "language": "python",
   "name": "pytorch-1.8.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
